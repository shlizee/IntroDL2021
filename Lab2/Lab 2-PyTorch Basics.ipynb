{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 2- PyTorch Basics.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EM6GQLv6j5uH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkXyuplZp4aQ"
      },
      "source": [
        "# Lab 2: PyTorch Basics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5dL4YeVorzV"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM6GQLv6j5uH"
      },
      "source": [
        "## Part 1: Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-ULM1BdkBMt"
      },
      "source": [
        "Tensors operate much like numpy arrays, but have additional properties which allow them to be used more easily in machine learning, such as being compatible with GPUs and other hardware accelerators and being optimized for automatic differentiation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDar-UyQmRXX"
      },
      "source": [
        "### Tensor Attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUCv1fUWnCOP"
      },
      "source": [
        "**Shape**: A tuple (n1, n2, ... nd) indicating the dimesions of the Tensor. To refer to a particular dimension, use `dim`, (instead of `axis` for `np.array`).\n",
        "\n",
        "\n",
        "**Datatype**: Form of the data stored in the Tensor. Common datatypes include `torch.float`, `torch.long`, `torch.bool`. See https://pytorch.org/docs/stable/tensors.html for full list.\n",
        "\n",
        "**Device**: Default device is `torch.device('cpu')`. If you want to use your GPU, be sure that your PyTorch installation has CUDA compatibility. If you have a GPU available, you can set the device to `torch.device('cuda')`\n",
        "\n",
        "*Note*: If you have more than 1 GPU available, you can choose which gpu you would like to use by providing a device index. For example, `torch.device('cuda:0')` or `torch.device('cuda', index= 0)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOOErpWtnMtk",
        "outputId": "af7eb568-e166-4d30-cb9c-543edea25a49"
      },
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcOH3zDFlp4V"
      },
      "source": [
        "### Tensor Initialization\n",
        "\n",
        "Like numpy arrays, Tensors can be initialized directly from data (in the form of a list or numpy array), or from random or constant values.\n",
        "\n",
        "Tensors can also be converted into numpy arrays using `numpy()`. To do this, the Tensor must have its device set to `cpu`, or it will cause an error. You can easily move a Tensor to the cpu using `cpu()`. Similarly, you can move a Tensor to the GPU using `cuda()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ2lCpkhkP0J",
        "outputId": "0d295025-4f0b-4be0-98c2-6efa1b96c155"
      },
      "source": [
        "#From data\n",
        "data = [[1, 2], [3,4]]\n",
        "x_data = torch.tensor(data)\n",
        "\n",
        "#From Numpy Array\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)\n",
        "\n",
        "#From anaother tensor\n",
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")\n",
        "\n",
        "x_np = x_rand.cpu().numpy() #Move tensor to the cpu and then convert to numpy array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.1273, 0.5640],\n",
            "        [0.8904, 0.4603]]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8vBJVhdku_N",
        "outputId": "abafcfd5-e3ee-4d21-b63e-5408f8a5a0a8"
      },
      "source": [
        "#Random and constant values\n",
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.3251, 0.5321, 0.3161],\n",
            "        [0.0860, 0.1050, 0.4700]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACK_7S2ypHne"
      },
      "source": [
        "### Tensor Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRV947xEpc40"
      },
      "source": [
        "Many of the artihmetic operations for Tensors are equivalent to those for numpy arrays, such as:\n",
        "<ul>\n",
        "<li>Indexing</li>\n",
        "<li>Slicing</li>\n",
        "<li>Matrix Multiplication (`@` or `tensor.matmul` )</li>\n",
        "<li>Elementwise Multiplication (`*` or `tensor.mul`)</li>\n",
        "<li>Addition and Subtraction</li>\n",
        "</ul>\n",
        "\n",
        "To concatenate two Tensors, the you use `torch.cat`, which is similar to `np.concatenate`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-BaS_mqpRyK",
        "outputId": "3fc92d18-931b-41a5-804b-22123f8e9d01"
      },
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "#Matrix Multiplication\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "#Elementwise Multiplication\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TPP5Pf6sRlS"
      },
      "source": [
        "Single-element items can be converted to a Python numerical value using `item()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0PgmlQPsO2d",
        "outputId": "7470088b-6f89-42fb-9f00-035111b68396"
      },
      "source": [
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16.0 <class 'float'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7o92VwQtweK"
      },
      "source": [
        "## Part 2: Neural Net Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my6ukgfhuyK0"
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5ol0c99w2MK"
      },
      "source": [
        "### Defining a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJT0OIxxt5tV"
      },
      "source": [
        "The base class for any model in PyTorch is `nn.Module`. Every model that you building should have a `forward` function, which defines how your model processes input data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-BsU5wit3kJ",
        "outputId": "b8cfd901-b352-414a-bc9e-d67c9890cbc1"
      },
      "source": [
        "class ExModel(nn.Module):\n",
        "  '''\n",
        "  Example model: A simple, two-layer NN with ReLU activation. \n",
        "  Input dimension is 100, output dimension is 1.\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    super(ExModel, self).__init__()\n",
        "    self.layer1 = nn.Linear(100, 50)\n",
        "    self.act1 = nn.ReLU()\n",
        "    self.output_layer = nn.Linear(50, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.act1(x)\n",
        "    output= self.output_layer(x)\n",
        "    return output\n",
        "\n",
        "\n",
        "model = ExModel()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ExModel(\n",
            "  (layer1): Linear(in_features=100, out_features=50, bias=True)\n",
            "  (act1): ReLU()\n",
            "  (output_layer): Linear(in_features=50, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibb5ihb0wJ4L"
      },
      "source": [
        "To process `input` using your model, simply call `model(input)`. Do not call `model.forward()` directly!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T91BlOenvwqH",
        "outputId": "bf04d138-c942-4f9c-94ea-6ee50b14edf8"
      },
      "source": [
        "batch_size = 64\n",
        "input = torch.rand(batch_size, 100)\n",
        "predictions = model(input)\n",
        "print(predictions.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18fzs361wcrx"
      },
      "source": [
        "### Graph-based computation: Parameters, Autograd, and Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P_4gM25v-aM"
      },
      "source": [
        "#Define hyperparameters for your training before initializing the optimizer\n",
        "learning_rate = 1e-1\n",
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebYA0EMu1xdK"
      },
      "source": [
        "**Loss Function**\n",
        "\n",
        "We start by defining a loss function. For Regression, the most common loss function is `nn.MSELoss` (Mean Square Error). For classification, the most common losses are `nn.NLLLoss` (Negative Log Likelihood) or `nn.CrossEntropy` (which combines `nn.LogSoftmax` and `nn/NLLLoss`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4igbJ41h2Ow2"
      },
      "source": [
        "#Initialize the loss Function\n",
        "loss_fn = nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYCKylms3D6p"
      },
      "source": [
        "**Optimizer**\n",
        "\n",
        "Choose the optimizer you wish to use from those found in `torch.optim`. Commonly used optimizers include `SGD` and `Adam`. You can find the full list at https://pytorch.org/docs/stable/optim.html.\n",
        "\n",
        "When you define the optimizer, you must give the parameters the optimizer is optimizing. If all your parameters are contained in your model class, you can access them using `model.parameters()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGpzAb2E3Ods"
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64LSRBG_4Fpp"
      },
      "source": [
        "**Training Steps**\n",
        "\n",
        "For each iteration in the training loop, optimization occurs in three steps:\n",
        "- Call `optimizer.zero_grad()` to reset the gradients of the model parameters. By default, the gradients accumulate, so this ensures that the optimizer is not double-counting </li>\n",
        "-Backpropagate the prediction loss with a call to `loss.backward()`. This causes PyTorch to deposit the gradients of the loss with respect to each parameter. </li>\n",
        "- Call `optimizer.step()` to update the parameters according to the optimization scheme and gradients calculated in the backwards pass. </li>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPhwmqpM5QUl",
        "outputId": "ab28b5c3-45cb-47e7-f5a6-95df69507510"
      },
      "source": [
        "#Randomly generate data and labels\n",
        "data = torch.rand(batch_size, 100)\n",
        "labels = torch.rand(batch_size, 1)\n",
        "epochs = 10\n",
        "\n",
        "#Training epochs\n",
        "for epoch in range(epochs):\n",
        "  optimizer.zero_grad()\n",
        "  out = model(data)           #Generate predictions using the model\n",
        "  loss = loss_fn(out, labels) #Loss/error\n",
        "  print(f'Training Loss: {loss:.4f}')\n",
        "  loss.backward()            #Propagate the gradients in backward pass\n",
        "  optimizer.step()           #Update the weights\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss: 0.0928\n",
            "Training Loss: 0.0866\n",
            "Training Loss: 0.0855\n",
            "Training Loss: 0.0845\n",
            "Training Loss: 0.0836\n",
            "Training Loss: 0.0828\n",
            "Training Loss: 0.0819\n",
            "Training Loss: 0.0811\n",
            "Training Loss: 0.0803\n",
            "Training Loss: 0.0795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFaq_ilu06Aa"
      },
      "source": [
        "### Saving and Loading Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQspRTe81BtE"
      },
      "source": [
        "The weights of a model are stored in a `state_dict`. You can train a model's state dictionary alone, or the entire model (including size and other hyperparameters). To load the weights of a model, use `model.load_statedict()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9twBhmrq0Ens"
      },
      "source": [
        "#Saving a model state_dict\n",
        "model = ExModel()\n",
        "torch.save(model.state_dict(), 'model_weights.pth')\n",
        "model.load_state_dict(torch.load('model_weights.pth'))  #Load model weights\n",
        "\n",
        "\n",
        "#Saving a full model\n",
        "model = ExModel()\n",
        "torch.save(model, 'model.pth')\n",
        "model = torch.load('model.pth') #Load full model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Pcy4gjq2Q6K"
      },
      "source": [
        "During training, you can also save the state of your optimizer, which similarly has a state dictionary. This is especially important if you are using momentum-based optimizers (such as Adam)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxkWe5Kl2hf4"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "torch.save(optimizer.state_dict(), 'optimizer_state.pth')\n",
        "optimizer.load_state_dict(torch.load('optimizer_state.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uenGHqZ277M"
      },
      "source": [
        "Often time, you might want to save many quantities at the same time when training a model. These can include:\n",
        "- Model weights/state\n",
        "- Optimizer weights/state\n",
        "- Training loss\n",
        "- Validation loss\n",
        "\n",
        "One common way to say all of these at once is using a dictionary. You can access all relevant quantities at a point in training in a single checkpoint.\n",
        "\n",
        "Note: You do not always need to save the model at each epoch. You may wish to define a `save_interval` to determine how often you save the weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt-j0Gmf3iyf"
      },
      "source": [
        "#Randomly generate data and labels\n",
        "data = torch.rand(batch_size, 100)\n",
        "labels = torch.rand(batch_size, 1)\n",
        "epochs = 10\n",
        "train_losses = []\n",
        "\n",
        "#Training epochs\n",
        "for epoch in range(epochs):\n",
        "  optimizer.zero_grad()\n",
        "  out = model(data)           #Generate predictions using the model\n",
        "  loss = loss_fn(out, labels) #Loss/error\n",
        "  train_loss.append(loss)\n",
        "  loss.backward()            #Propagate the gradients in backward pass\n",
        "  optimizer.step()\n",
        "  ckpt = {'train_losses': train_losses, 'model_weights': model.state_dict(),  # Define checkpoint\n",
        "          'optimizer_state': optimizer.state_dict()}                          # dictionary\n",
        "  torch.save(ckpt, f'trained_model_e{epoch}.ckpt')  #Save checkpoint for each epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Gid_b2tyw8_"
      },
      "source": [
        "## Example: Iris Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRj-ie8Vy67K"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris['data']\n",
        "y = iris['target']\n",
        "names = iris['target_names']\n",
        "feature_names = iris['feature_names']\n",
        "\n",
        "# Scale data to have mean 0 and variance 1 \n",
        "# which is importance for convergence of the neural network\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data set into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjRBl-240fzm"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "for target, target_name in enumerate(names):\n",
        "    X_plot = X[y == target]\n",
        "    ax1.plot(X_plot[:, 0], X_plot[:, 1], \n",
        "             linestyle='none', \n",
        "             marker='o', \n",
        "             label=target_name)\n",
        "ax1.set_xlabel(feature_names[0])\n",
        "ax1.set_ylabel(feature_names[1])\n",
        "ax1.axis('equal')\n",
        "ax1.legend();\n",
        "\n",
        "for target, target_name in enumerate(names):\n",
        "    X_plot = X[y == target]\n",
        "    ax2.plot(X_plot[:, 2], X_plot[:, 3], \n",
        "             linestyle='none', \n",
        "             marker='o', \n",
        "             label=target_name)\n",
        "ax2.set_xlabel(feature_names[2])\n",
        "ax2.set_ylabel(feature_names[3])\n",
        "ax2.axis('equal')\n",
        "ax2.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX6J7qO50em2"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, 50)\n",
        "        self.layer2 = nn.Linear(50, 50)\n",
        "        self.layer3 = nn.Linear(50, 3)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        x = F.softmax(self.layer3(x), dim=1)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_cmxgxD0nN4"
      },
      "source": [
        "model     = Model(X_train.shape[1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn   = nn.CrossEntropyLoss()\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyt-DraC1gVV"
      },
      "source": [
        "import tqdm\n",
        "\n",
        "EPOCHS  = 100\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "y_train = torch.from_numpy(y_train).long()\n",
        "X_test  = torch.from_numpy(X_test).float()\n",
        "y_test  = torch.from_numpy(y_test).long()\n",
        "\n",
        "loss_list     = np.zeros((EPOCHS,))\n",
        "accuracy_list = np.zeros((EPOCHS,))\n",
        "\n",
        "for epoch in tqdm.trange(EPOCHS):\n",
        "    y_pred = model(X_train)\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "    loss_list[epoch] = loss.item()\n",
        "    \n",
        "    # Zero gradients\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        y_pred = model(X_test)\n",
        "        correct = (torch.argmax(y_pred, dim=1) == y_test).type(torch.FloatTensor)\n",
        "        accuracy_list[epoch] = correct.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHKYZP0o3cdC"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(2, figsize=(12, 6), sharex=True)\n",
        "\n",
        "ax1.plot(accuracy_list)\n",
        "ax1.set_ylabel(\"validation accuracy\")\n",
        "ax2.plot(loss_list)\n",
        "ax2.set_ylabel(\"training loss\")\n",
        "ax2.set_xlabel(\"epochs\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7h7N_1X4lmI"
      },
      "source": [
        "## Lab Assignment: MNIST Classification Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0vR5I9h4s8V"
      },
      "source": [
        "Design your own MNIST Classification model (see video recording for explanation of MNIST dataset). You may choose your own hyperparameters, including:\n",
        "- Number of layers\n",
        "- Number of neurons in each layer\n",
        "- Learning rate\n",
        "- Number of training epochs\n",
        "- Optimizer\n",
        "\n",
        "Using a fully-connected network, you should be able to accomplish >90% accuracy on the test set. Please report your hyperparameter selections and accuracy in a summary at the end of the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly85jvec6V6A"
      },
      "source": [
        "To load the MNIST dataset, we will use `torchvision`, which contains the datasets and has useful transformations. Start by defining the batch size you want for your training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feGo1EKE4sRg"
      },
      "source": [
        "import torchvision\n",
        "train_batch_size = #Define train batch size\n",
        "test_batch_size  = #Define test batch size (can be larger than train batch size)\n",
        "\n",
        "\n",
        "# Use the following code to load and normalize the dataset\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=batch_size_test, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrvoPg1f7Gxu"
      },
      "source": [
        "#Define your network:\n",
        "class Network(nn.Module):\n",
        "  def __init__(self): #Can provide additional inputs for initialization\n",
        "    #Define the network layer(s) and activation function(s)\n",
        "\n",
        "  def forward(self, input):\n",
        "    #How does your model process the input?\n",
        "\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F_DyktW8Bgw"
      },
      "source": [
        "#Define your optimizer\n",
        "model = Network()\n",
        "optimizer =\n",
        "epochs =\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for train_sample in train_loader:\n",
        "    #Calculate training loss on model\n",
        "\n",
        "#Calculate loss on test set\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdpBAsgdbLK-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_cv, y_train, y_cv = train_test_split(features, labels, \n",
        "                                                test_size = 0.2,\n",
        "                                                random_state = 1212)\n",
        "\n",
        "X_train = np.array(X_train).reshape(33600, 784) #(33600, 784)\n",
        "X_cv = np.array(X_cv).reshape(8400, 784) #(8400, 784)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqnEUuaAby8q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR2MwC2mcIz4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac1wn7CKcMns"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}