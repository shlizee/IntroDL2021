{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 9 AMATH - Autoencoders.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXosh4UcyboN"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufWOuXrilT_8"
      },
      "source": [
        "# Autoencoder Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL4RMuuD5JPi"
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self, input_size, latent_size, p_drop = 0.2):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    \n",
        "    self.drop = nn.Dropout(p = p_drop)\n",
        "\n",
        "    #Define Encoder Layers\n",
        "    self.fc_e1 = nn.Linear(in_features = input_size, out_features = input_size//8)\n",
        "    self.fc_e2 = nn.Linear(in_features = input_size//8, out_features = latent_size)\n",
        "\n",
        "    #Define Decoder Layers\n",
        "    self.fc_d1 = nn.Linear(in_features = latent_size, out_features = input_size//4)\n",
        "    self.fc_d2 = nn.Linear(in_features = input_size//4, out_features = input_size)\n",
        "\n",
        "  def forward(self, input):\n",
        "    enc = self.drop(nn.Tanh()(self.fc_e1(input)))\n",
        "    latent = self.fc_e2(enc)\n",
        "    dec = self.drop(nn.Tanh()(self.fc_d1(latent)))\n",
        "    output = self.fc_d2(dec)\n",
        "    return output, latent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QXZxb557_H0"
      },
      "source": [
        "X = torch.rand(64, 256)\n",
        "ae = Autoencoder(input_size= 256, latent_size = 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpFLE9S3eZ66"
      },
      "source": [
        "# Example: MNIST AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbdd13Xnectj"
      },
      "source": [
        "import torchvision\n",
        "from math import floor, ceil\n",
        "batch_size_train = 64 #Define train batch size\n",
        "batch_size_test  = 256 #Define test batch size (can be larger than train batch size)\n",
        "\n",
        "\n",
        "# Use the following code to load and normalize the dataset\n",
        "train_set = torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                              transform=torchvision.transforms.Compose([\n",
        "                                torchvision.transforms.ToTensor(),\n",
        "                                torchvision.transforms.Normalize(\n",
        "                                  (0.1307,), (0.3081,))\n",
        "                              ]))\n",
        "\n",
        "\n",
        "test_set = torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiNhJ-pBe5QO"
      },
      "source": [
        "train_set[0][0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ2yS5e7fMcM"
      },
      "source": [
        "train_set, val_set = torch.utils.data.random_split(train_set, [floor(len(train_set)*0.8), ceil(len(train_set)*0.2)])\n",
        "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size = batch_size_train, shuffle = True)\n",
        "val_dataloader  = torch.utils.data.DataLoader(val_set, batch_size = batch_size_test, shuffle = False)\n",
        "test_dataloader  = torch.utils.data.DataLoader(test_set, batch_size = batch_size_test, shuffle = False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6anX_Slnf8eL"
      },
      "source": [
        "max_epochs = 30\n",
        "learning_rate = 0.001\n",
        "input_size = 28*28\n",
        "latent_size = 32\n",
        "model = Autoencoder(input_size, latent_size)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "criterion = torch.nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg7dIqkihS9G"
      },
      "source": [
        "from tqdm import tqdm\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "for epoch in tqdm(range(max_epochs)):\n",
        "  model.train()\n",
        "  for i, sample in enumerate(train_dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    data, label = sample\n",
        "    data_in = data.view(data.shape[0], input_size)\n",
        "    output = model(data_in)[0]\n",
        "    loss = criterion(data_in, output)\n",
        "    loss.backward()\n",
        "    train_losses.append(loss.item())\n",
        "    optimizer.step()\n",
        "  model.eval()\n",
        "  vl = 0\n",
        "  with torch.no_grad():\n",
        "    for sample in val_dataloader:\n",
        "      data, label = sample\n",
        "      data_in = data.view(data.shape[0], input_size)\n",
        "      output = model(data_in)[0]\n",
        "      loss = criterion(data_in, output)\n",
        "      vl += loss.item()\n",
        "  val_losses.append(vl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO5BGaXRj1N7"
      },
      "source": [
        "plt.plot(val_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkCOrOw2muH3"
      },
      "source": [
        "inds = torch.randint(low = 0, size = (8,), high = len(test_set))\n",
        "samples = 5\n",
        "f, ax = plt.subplots(samples, 2, figsize = (3, 8))\n",
        "for i, idx in enumerate(inds[:samples]):\n",
        "  ax[i,1].imshow(model(test_set[idx][0].flatten().unsqueeze(0))[0].view(28, 28).detach())\n",
        "  ax[i,0].imshow(test_set[idx][0][0])\n",
        "f.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgF6w4R8rB13"
      },
      "source": [
        "test_dataloader = torch.utils.data.DataLoader(test_set, \n",
        "                              batch_size = 10000, shuffle = False)\n",
        "labels = torch.zeros((0,))\n",
        "for sample in test_dataloader:\n",
        "  data = sample[0]\n",
        "  data_in = data.view(data.shape[0], -1)\n",
        "  latents = model(data_in)[1]\n",
        "  labels = torch.hstack([labels, sample[1]])\n",
        "U, S, V = torch.pca_lowrank(latents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9HKUGGXrty4"
      },
      "source": [
        "plt.figure(figsize = (8,6))\n",
        "for i in range(10):\n",
        "  mask = labels == i\n",
        "  Y = (U[mask]@torch.diag(S)).detach()\n",
        "  plt.scatter(Y[:,0], Y[:,1], label = i, alpha = 0.4, s = 10)\n",
        "  plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV8o_XXUFqgE"
      },
      "source": [
        "full_test = torch.zeros((0, 784))\n",
        "labels = torch.zeros((0,))\n",
        "for sample in test_dataloader:\n",
        "  full_test = torch.vstack([full_test, sample[0].view(-1, 784)])\n",
        "  labels = torch.hstack([labels, sample[1]])\n",
        "U, S, V = torch.svd(full_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWG2iKX8GOb9"
      },
      "source": [
        "for i in range(10):\n",
        "  mask = labels.long() == i\n",
        "  Y = (U[mask]@torch.diag(S)).detach()\n",
        "  plt.scatter(Y[:,0], Y[:,1], label = i, alpha = 0.4, s = 7)\n",
        "  plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qog7F6dKxYue"
      },
      "source": [
        "# Assignment: Enhanced Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYDxc6l-xboi"
      },
      "source": [
        "class EnhancedAutoencoder(nn.Module):\n",
        "  def __init__(self, input_size, latent_size, p_drop = 0.2):\n",
        "    super(EnhancedAutoencoder, self).__init__()\n",
        "    \n",
        "    self.drop = nn.Dropout(p = p_drop)\n",
        "\n",
        "    #Define Encoder Layers\n",
        "\n",
        "\n",
        "    #Define Decoder Layers\n",
        "\n",
        "\n",
        "  def forward(self, input):\n",
        "    #Define forward\n",
        "    return output, latent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqKMDEbD5IrO"
      },
      "source": [
        "# If implementing VAE:\n",
        "def kld_loss(mus, vars):\n",
        "  # Define KLD loss with standard normal prior\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOwjty5544VH"
      },
      "source": [
        "## Sample VAE Implementation (Change this if using for for Assignment)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkOk2v1z0v0e"
      },
      "source": [
        "class ExampleVAE(nn.Module):\n",
        "  def __init__(self, input_size, latent_size, p_drop = 0.2):\n",
        "    super(ExampleVAE, self).__init__()\n",
        "    \n",
        "    self.drop = nn.Dropout(p = p_drop)\n",
        "\n",
        "    #Define Encoder Layers\n",
        "    self.fc_e1 = nn.Linear(in_features = input_size, out_features = input_size//8)\n",
        "    self.fc_e2_1 = nn.Linear(in_features = input_size//8, out_features = latent_size)\n",
        "    self.fc_e2_2 = nn.Linear(in_features = input_size//8, out_features = latent_size)\n",
        "\n",
        "    #Define Decoder Layers\n",
        "    self.fc_d1 = nn.Linear(in_features = latent_size, out_features = input_size//4)\n",
        "    self.fc_d2 = nn.Linear(in_features = input_size//4, out_features = input_size)\n",
        "\n",
        "  def forward(self, input):\n",
        "    enc = self.drop(nn.Tanh()(self.fc_e1(input)))\n",
        "    mus = self.fc_e2_1(enc) #means of latent Gaussian\n",
        "    var =self.fc_e2_2(enc)  #(log) var of latent Gaussian\n",
        "    sample = self.reparameterize(mus, var)\n",
        "\n",
        "    dec = self.drop(nn.Tanh()(self.fc_d1(sample)))\n",
        "    output = self.fc_d2(dec)\n",
        "    return output, (mus, var)\n",
        "\n",
        "  def reparameterize(self, mu, logvar):\n",
        "    '''\n",
        "    Used to generate sample from latent Gaussian\n",
        "    '''\n",
        "    std = torch.exp(0.5 * logvar)\n",
        "    eps = torch.randn_like(std)\n",
        "    return eps * std + mu"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}