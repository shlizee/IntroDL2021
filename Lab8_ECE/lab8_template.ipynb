{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd22dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the installation of OpenAI Gym use the following command in anaconda prompt\n",
    "# conda install -c conda-forge gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe3d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a22fb26",
   "metadata": {},
   "source": [
    "## Import cartpole from OpenAI Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "env.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate =\n",
    "gamma = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb60182d",
   "metadata": {},
   "source": [
    "## Define your Deep RL Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd6e404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR DEEP RL ARCHITECTURE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd9f061",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667963d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for general case - Feel free to modify for your needs\n",
    "\n",
    "def train(episodes):\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        # Reset environment and record the starting state\n",
    "        state = env.reset()\n",
    "\n",
    "        for time in range(1000):\n",
    "            \n",
    "            action = choose_action(state) # Your agent's function of choosing action\n",
    "\n",
    "            # Uncomment to render the visual state in a window during training\n",
    "            # env.render()\n",
    "\n",
    "            # Step through environment using chosen action\n",
    "            state, reward, done, _ = env.step(action)\n",
    "\n",
    "            if done:\n",
    "                \n",
    "                break\n",
    "\n",
    "        # Calculate score to determine when the environment has been solved (Last 100 episodes last >475 frames)\n",
    "        scores.append(time)\n",
    "        mean_score = np.mean(scores[-100:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d86a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = \n",
    "optimizer = \n",
    "train(episodes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159f3de3",
   "metadata": {},
   "source": [
    "## Render the cartpole controlled by trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1300aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frames_as_gif(frames, filename='gym_animation.mp4'):\n",
    "\n",
    "    #Mess with this to change frame size\n",
    "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
    "\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=1)\n",
    "    anim.save(filename + '.mp4', writer='ffmpeg', fps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09a750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to generate .mp4 file of cartpole rendering controlled by your trained agent\n",
    "\n",
    "frames = []\n",
    "\n",
    "state = env.reset()\n",
    "\n",
    "for t in range(1000):\n",
    "    \n",
    "    action = choose_action(state)\n",
    "    \n",
    "    frames.append(env.render(mode=\"rgb_array\"))\n",
    "\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    \n",
    "    if done:\n",
    "        \n",
    "        break\n",
    "\n",
    "env.close()\n",
    "\n",
    "save_frames_as_gif(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1ccd11",
   "metadata": {},
   "source": [
    "## Plot the training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d435904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the reward throughout training (running average over 50 episodes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
